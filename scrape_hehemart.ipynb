{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **WEB SCRAPING FROM HEHEMART'S WEBSITE** *with BeautifulSoup*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "This project is an opportunity to apply my web scraping skills to extract public data from [Hehe Mart](https://shop.mart.rw/categories-en-3/groceries/vegetables).\n",
    "\n",
    "The objective is to explore discounts the store offers. This objective might expand and grow into more interesting things.\n",
    "\n",
    "I also checked (since it's important) if webscraping from HeheMart will be in violation of their privacy policy. Fortunately, it isn't.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing HTML to BeautifulSoup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to vegetables page in hehemart's website\n",
    "my_url = 'https://shop.mart.rw/categories-en-3/groceries/vegetables'\n",
    "\n",
    "# opening up a conection and grabbing the page\n",
    "uClient = uReq(my_url)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "\n",
    "# html parsing\n",
    "page_soup = soup(page_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the HTML Structure and Extraction\n",
    "\n",
    "I inspected the html page in the browser and noticed that each product listed on the page lives within a div element with class titled \"ty-column4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting all conatiners of products in the webpage\n",
    "containers = page_soup.findAll(\"div\",{\"class\":\"ty-column4\"})\n",
    "\n",
    "len(containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is the number of products on this page (displayed above). My guess is that it's slightly less because some of these div elements may not contain a product.\n",
    "We'll have to do some investigation later.\n",
    "\n",
    "---\n",
    "\n",
    "I'm interested in the following details of each product:\n",
    "* Product Name\n",
    "* Price\n",
    "* Currency\n",
    "* Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "I decide to test the extraction with the first container to see if it works\n",
    "\n",
    "What I notice is that there are two span elements each with the class name \"ty-price-num\". I realized the first refers to the price and the second refers to the currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name: Tomatoes (Open Field) (kg)\n",
      "Price: 1,690\n",
      "Currency: RWF\n",
      "Unit: / Kg\n"
     ]
    }
   ],
   "source": [
    "# test with first container (product_name, price, currency, unit)\n",
    "\n",
    "container = containers[0]\n",
    "\n",
    "product_name = container.find(\"div\",{\"class\":\"ty-grid-list__item-name\"}).bdi.a.text\n",
    "price = container.findAll(\"span\",\"ty-price-num\")[0].string\n",
    "curr = container.findAll(\"span\",\"ty-price-num\")[1].string\n",
    "unit = container.findAll(\"span\",\"unit-price-line1\")[0].p.string\n",
    "\n",
    "print(\"Product Name:\", product_name)\n",
    "print(\"Price:\", price)\n",
    "print(\"Currency:\", curr)\n",
    "print(\"Unit:\", unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "So far, so good.\n",
    "\n",
    "A few points though:\n",
    "* Checking the webpage, not all the products have units so we'd have to catch those exceptions. *An example is the **Amaranth (Dodo)** product. It has no unit.*\n",
    "* Also, each unit has a slash and a whitespace. I'd probably do this in pandas with regex to extract just the unit. Eg: \"/ Kg\" --> \"Kg\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following gives us the exception errors and the indices of the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display index of divs in containers that are throwing errors\n",
    "def where_errors(container_list):\n",
    "    counter=-1\n",
    "    counter_list=[]\n",
    "\n",
    "    for container in container_list:\n",
    "        counter+=1\n",
    "        try:\n",
    "            container.findAll(\"span\",\"unit-price-line1\")[0]\n",
    "        except IndexError:\n",
    "            pass\n",
    "            counter_list.append(counter)\n",
    "    \n",
    "    return counter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39, 47, 49, 50, 51]\n"
     ]
    }
   ],
   "source": [
    "index_of_errors = where_errors(containers)\n",
    "print(index_of_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now that we know where these errors are, let's find their product names so we can investigate what the issue is in the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amaranth (Dodo) - 39\n",
      "Green Box - 47\n",
      "Exotic Box - 49\n",
      "div tag index 50 still has an error\n",
      "div tag index 51 still has an error\n"
     ]
    }
   ],
   "source": [
    "# check if these errors don't have units\n",
    "\n",
    "for i in index_of_errors:\n",
    "    try:\n",
    "        container_e = containers[i]\n",
    "        product_name = container_e.find(\"div\",{\"class\":\"ty-grid-list__item-name\"}).bdi.a.string\n",
    "\n",
    "        print(product_name, \"-\", i)\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "        print(\"div tag index\", i, \"still has an error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing empty divs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After webpage inspection, we realize that 39, 47 and 49 represent divs of products that don't have a unit. We would have to extract as blank.\n",
    "\n",
    "With 50 and 51 though, they don't contain anything at all. Let's confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"ty-column4\"></div>\n",
      "<div class=\"ty-column4\"></div>\n"
     ]
    }
   ],
   "source": [
    "print(containers[50])\n",
    "print(containers[51])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's remove the empty containers from the list. Any container that's not empty will have a length of more than 0 so that's what we'd use as the criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 50 products from the webpage we can start extracting from\n"
     ]
    }
   ],
   "source": [
    "containers_clean = [s for s in containers if len(s) > 0]\n",
    "\n",
    "print(\"We now have\", len(containers_clean), \"products from the webpage we can start extracting from\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write extracted data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # csv create to dump data in\n",
    "# filename = 'products_hehe.csv'\n",
    "# f = open(filename, 'w')\n",
    "\n",
    "# # creating headers for the csv file\n",
    "# headers = \"product_name, price, currency, unit\\n\"\n",
    "# f.write(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for container in containers:\n",
    "#     product_name = container.find(\"div\",{\"class\":\"ty-grid-list__item-name\"}).bdi.a.text\n",
    "#     price = container.findAll(\"span\",\"ty-price-num\")[0].string\n",
    "\n",
    "#     # write to csv\n",
    "#     f.write(brand + \",\" + product_name.replace(\",\",\"|\") + \",\" + shipping + \"\\n\")\n",
    "\n",
    "# f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
